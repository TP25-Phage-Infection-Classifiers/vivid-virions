{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca54706c",
   "metadata": {},
   "source": [
    "# User Story 14 / 15\n",
    "@LuiseJedlitschka\n",
    "\n",
    "**Cross-Validation Strategy: Leave-One-Group-Out**\n",
    "\n",
    "To evaluate the generalization capability of our models and to avoid overfitting, we employed the leave-one-group-out cross-validation strategy as implemented in scikit-learn. In this approach, each dataset —corresponding to a specific phage— is used once as the test set (singleton), while the remaining datasets collectively form the training set. This ensures that, in each split, the model is validated on data from a phage that was not seen during training, providing a robust assessment of performance across different biological backgrounds.\n",
    "\n",
    "Note:\n",
    "- The data was not explicitly stratified according to the classification classes (\"early\", \"middle\", \"late\") during the splitting process as that is not part of the leave-one-group-out strategy. As a result, the distribution of these classes may vary between the training and test sets in each split.\n",
    "- due to its very unusal class distribution the sprenger data set is completely being left out for now\n",
    "\n",
    "An overview of the class distribution in the training and test sets for each split is provided in\n",
    "leave_one_group_out_split/overview.tsv.\n",
    "\n",
    "All corresponding training and test files for each split are saved in\n",
    "data/leave-one-group-out-stratified-split/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78705fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1164, 85); y_train: (1164,)\n",
      "X_train: (54, 85); y_train: (54,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       early       0.25      0.33      0.29         3\n",
      "        late       0.74      0.78      0.76        32\n",
      "      middle       0.62      0.53      0.57        19\n",
      "\n",
      "    accuracy                           0.67        54\n",
      "   macro avg       0.54      0.55      0.54        54\n",
      "weighted avg       0.67      0.67      0.67        54\n",
      "\n",
      "Split 0: No overlapping genes.\n",
      "X_train: (981, 85); y_train: (981,)\n",
      "X_train: (237, 85); y_train: (237,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       early       0.38      0.26      0.31        78\n",
      "        late       0.29      0.41      0.34        59\n",
      "      middle       0.39      0.40      0.39       100\n",
      "\n",
      "    accuracy                           0.35       237\n",
      "   macro avg       0.36      0.35      0.35       237\n",
      "weighted avg       0.36      0.35      0.35       237\n",
      "\n",
      "Split 1: No overlapping genes.\n",
      "X_train: (930, 85); y_train: (930,)\n",
      "X_train: (288, 85); y_train: (288,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       early       0.73      0.15      0.25       162\n",
      "        late       0.45      0.64      0.53       117\n",
      "      middle       0.01      0.11      0.02         9\n",
      "\n",
      "    accuracy                           0.35       288\n",
      "   macro avg       0.40      0.30      0.27       288\n",
      "weighted avg       0.59      0.35      0.35       288\n",
      "\n",
      "Split 2: No overlapping genes.\n",
      "X_train: (1158, 85); y_train: (1158,)\n",
      "X_train: (60, 85); y_train: (60,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       early       0.06      0.14      0.08         7\n",
      "        late       0.38      0.52      0.44        21\n",
      "      middle       0.36      0.16      0.22        32\n",
      "\n",
      "    accuracy                           0.28        60\n",
      "   macro avg       0.27      0.27      0.25        60\n",
      "weighted avg       0.33      0.28      0.28        60\n",
      "\n",
      "Split 3: No overlapping genes.\n",
      "X_train: (757, 85); y_train: (757,)\n",
      "X_train: (461, 85); y_train: (461,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       early       0.10      0.39      0.15        46\n",
      "        late       0.57      0.42      0.48       209\n",
      "      middle       0.42      0.24      0.31       206\n",
      "\n",
      "    accuracy                           0.34       461\n",
      "   macro avg       0.36      0.35      0.32       461\n",
      "weighted avg       0.45      0.34      0.37       461\n",
      "\n",
      "Split 4: No overlapping genes.\n",
      "X_train: (1154, 85); y_train: (1154,)\n",
      "X_train: (64, 85); y_train: (64,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       early       0.00      0.00      0.00         0\n",
      "        late       1.00      0.48      0.65        64\n",
      "      middle       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.48        64\n",
      "   macro avg       0.33      0.16      0.22        64\n",
      "weighted avg       1.00      0.48      0.65        64\n",
      "\n",
      "Split 5: No overlapping genes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam_linux/miniconda3/envs/vividVirions/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/sam_linux/miniconda3/envs/vividVirions/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/sam_linux/miniconda3/envs/vividVirions/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1164, 85); y_train: (1164,)\n",
      "X_train: (54, 85); y_train: (54,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       early       0.30      0.67      0.41         9\n",
      "        late       0.58      0.65      0.61        23\n",
      "      middle       0.50      0.18      0.27        22\n",
      "\n",
      "    accuracy                           0.46        54\n",
      "   macro avg       0.46      0.50      0.43        54\n",
      "weighted avg       0.50      0.46      0.44        54\n",
      "\n",
      "Split 6: No overlapping genes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "# Directory with the TSV files\n",
    "directory = \"../data/feature_tables\"\n",
    "# Output directory\n",
    "output_dir = \"../data/leave-one-group-out-split\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List of all .tsv files in the directory\n",
    "tsv_files = glob.glob(os.path.join(directory, \"*.tsv\"))\n",
    "\n",
    "# Combine all TSV files into a Dataframe, for each dataset assign the group-name\n",
    "\n",
    "df = pd.concat(\n",
    "    [pd.read_csv(f, sep=\"\\t\").assign(group=os.path.basename(f)) for f in tsv_files],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "# save combined table containing features and group index of each gene\n",
    "output_path = os.path.join(output_dir, \"combined.tsv\")\n",
    "df.to_csv(output_path, sep=\"\\t\", index=False)\n",
    "\n",
    "# Prepare subfolder for splits\n",
    "splits_dir = os.path.join(output_dir, \"splits\")\n",
    "os.makedirs(splits_dir, exist_ok=True)\n",
    "\n",
    "# Perform split of one group each as test -> 6 splits\n",
    "logo = LeaveOneGroupOut()\n",
    "results = []\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(logo.split(df, groups=df[\"group\"])):\n",
    "    train_df = df.iloc[train_idx]\n",
    "    test_df = df.iloc[test_idx]\n",
    "\n",
    "    # save train and test data for this split\n",
    "    train_path = os.path.join(splits_dir, f\"train_split_{i}.tsv\")\n",
    "    test_path = os.path.join(splits_dir, f\"test_split_{i}.tsv\")\n",
    "    train_df.to_csv(train_path, sep=\"\\t\", index=False)\n",
    "    test_df.to_csv(test_path, sep=\"\\t\", index=False)\n",
    "\n",
    "    test_model(train_df, test_df)\n",
    "\n",
    "    # overall class distribution\n",
    "    all_classes = sorted(df[\"classification_x\"].unique())\n",
    "\n",
    "    # class distribution in train set\n",
    "    train_counts = train_df[\"classification_x\"].value_counts(normalize=True)\n",
    "    # class distribution in test set\n",
    "    test_counts = test_df[\"classification_x\"].value_counts(normalize=True)\n",
    "\n",
    "    # Check for overlapping genes\n",
    "    overlapping_genes = set(train_df[\"Geneid\"]).intersection(set(test_df[\"Geneid\"]))\n",
    "    if overlapping_genes:\n",
    "        print(f\"Split {i}: {len(overlapping_genes)} overlapping genes found!\")\n",
    "    else:\n",
    "        print(f\"Split {i}: No overlapping genes.\")\n",
    "\n",
    "    for cls in all_classes:\n",
    "        results.append(\n",
    "            {\n",
    "                \"split\": i,\n",
    "                \"group_left_out\": df.iloc[test_idx][\"group\"].iloc[\n",
    "                    0\n",
    "                ],  # number of the test group\n",
    "                \"class\": cls,\n",
    "                \"train_ratio\": train_counts.get(cls, 0),\n",
    "                \"test_ratio\": test_counts.get(cls, 0),\n",
    "                \"train_count\": train_df[\"classification_x\"].value_counts().get(cls, 0),\n",
    "                \"test_count\": test_df[\"classification_x\"].value_counts().get(cls, 0),\n",
    "            }\n",
    "        )\n",
    "\n",
    "# convert results to DataFrame\n",
    "split_summary = pd.DataFrame(results)\n",
    "\n",
    "# Save overview of each split\n",
    "overview_path = os.path.join(output_dir, \"logo_class_distributions.tsv\")\n",
    "split_summary.to_csv(overview_path, sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849f5b4",
   "metadata": {},
   "source": [
    "| Metric        | Meaning                                                                                                                                                |\n",
    "| ------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **precision** | Out of all predicted instances of a class, how many were actually correct?<br>**Formula**: TP / (TP + FP)                                              |\n",
    "| **recall**    | Out of all actual instances of a class, how many did the model correctly detect?<br>**Formula**: TP / (TP + FN)                                        |\n",
    "| **f1-score**  | Harmonic mean of precision and recall.<br>Good single metric for imbalanced classes.<br>**Formula**: 2 \\* (precision \\* recall) / (precision + recall) |\n",
    "| **support**   | Number of true examples of each class in the dataset.   |\n",
    "| **accuracy**     | Overall: (correct predictions) / (total samples)                                                                                 |\n",
    "| **macro avg**    | Unweighted average across all classes.<br>Each class contributes equally (good for comparing classes).                           |\n",
    "| **weighted avg** | Weighted average, where each class's contribution is proportional to its support.<br>More realistic when classes are imbalanced. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a81d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def test_model(train_df, test_df):\n",
    "    le = LabelEncoder()\n",
    "    le.fit_transform(train_df[\"classification_x\"])\n",
    "\n",
    "    feature_cols = (\n",
    "        df.iloc[train_idx]\n",
    "        .drop(\n",
    "            columns=[\"Unnamed: 0\", \"Geneid\", \"DNASequence\", \"classification_x\", \"group\"]\n",
    "        )\n",
    "        .columns\n",
    "    )\n",
    "\n",
    "    X_train = train_df[feature_cols]\n",
    "    y_train = train_df[\"classification_x\"]\n",
    "\n",
    "    X_val = test_df[feature_cols]\n",
    "    y_val = test_df[\"classification_x\"]\n",
    "\n",
    "    print(f\"X_train: {X_train.shape}; y_train: {y_train.shape}\")\n",
    "    print(f\"X_train: {X_val.shape}; y_train: {y_val.shape}\")\n",
    "\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_val)\n",
    "    print(classification_report(y_val, y_pred, target_names=le.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vividVirions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
