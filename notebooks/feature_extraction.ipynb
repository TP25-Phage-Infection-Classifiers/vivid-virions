{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8fed2757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez, SeqIO\n",
    "from Bio.SeqUtils import gc_fraction\n",
    "from Bio.Seq import Seq\n",
    "from itertools import product\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from BCBio import GFF\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8548bd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Processing: Brandao_MCCM_full_raw_counts_tpm_filtered_classified.tsv\n",
      "âœ… Saved to: ../data/feature_extraction\\Brandao_MCCM_full_raw_counts_tpm_filtered_classified.tsv\n",
      "ðŸ” Processing: Finstrlova_Newman_full_raw_counts_tpm_filtered_classified.tsv\n",
      "âœ… Saved to: ../data/feature_extraction\\Finstrlova_Newman_full_raw_counts_tpm_filtered_classified.tsv\n",
      "ðŸ” Processing: Guegler_T4_minusToxIN_full_raw_counts_tpm_filtered_classified.tsv\n",
      "âœ… Saved to: ../data/feature_extraction\\Guegler_T4_minusToxIN_full_raw_counts_tpm_filtered_classified.tsv\n",
      "ðŸ” Processing: Guegler_T7_plusToxIN_full_raw_counts_tpm_filtered_classified.tsv\n",
      "âœ… Saved to: ../data/feature_extraction\\Guegler_T7_plusToxIN_full_raw_counts_tpm_filtered_classified.tsv\n",
      "ðŸ” Processing: Lood_full_raw_counts_tpm_filtered_classified.tsv\n",
      "âœ… Saved to: ../data/feature_extraction\\Lood_full_raw_counts_tpm_filtered_classified.tsv\n",
      "ðŸ” Processing: Sprenger_VC_WT_VP882_delta_cpdS_full_raw_counts_tpm_filtered_classified.tsv\n",
      "âœ… Saved to: ../data/feature_extraction\\Sprenger_VC_WT_VP882_delta_cpdS_full_raw_counts_tpm_filtered_classified.tsv\n",
      "ðŸ” Processing: Yang_full_raw_counts_tpm_filtered_classified.tsv\n",
      "âœ… Saved to: ../data/feature_extraction\\Yang_full_raw_counts_tpm_filtered_classified.tsv\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"../data/classified\"\n",
    "output_folder = \"../data/feature_extraction\"\n",
    "\n",
    "# Map each input file to its matching genome accession\n",
    "genome_mapping = {\n",
    "    \"Brandao_MCCM_full_raw_counts_tpm_filtered_classified.tsv\": \"NC_010326\",\n",
    "    \"Finstrlova_Newman_full_raw_counts_tpm_filtered_classified.tsv\": \"NC_005880\",\n",
    "    \"Guegler_T4_minusToxIN_full_raw_counts_tpm_filtered_classified.tsv\": \"NC_000866\",\n",
    "    \"Guegler_T7_plusToxIN_full_raw_counts_tpm_filtered_classified.tsv\": \"NC_001604\",\n",
    "    \"Lood_full_raw_counts_tpm_filtered_classified.tsv\": \"MK797984.1\",\n",
    "    \"Sprenger_VC_WT_VP882_delta_cpdS_full_raw_counts_tpm_filtered_classified.tsv\": \"NC_009016.1\",\n",
    "    \"Yang_full_raw_counts_tpm_filtered_classified.tsv\": \"NC_021316\",\n",
    "}\n",
    "\n",
    "# Make sure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# ---- FUNCTION TO GET PROTEIN + DNA SEQUENCE ----\n",
    "def get_sequences_from_geneid(genome_accession, geneid):\n",
    "    try:\n",
    "        handle = Entrez.efetch(db=\"nucleotide\", id=genome_accession, rettype=\"gb\", retmode=\"text\")\n",
    "        record = SeqIO.read(handle, \"genbank\")\n",
    "        handle.close()\n",
    "    except Exception as e:\n",
    "        print(f\"âš  Failed to fetch {genome_accession}: {e}\")\n",
    "        return (\"ERROR_FETCH\", \"ERROR_FETCH\")\n",
    "\n",
    "    tag = geneid.replace(\"gene-\", \"\").strip()\n",
    "    short_tag = tag.split(\"_\")[-1]\n",
    "\n",
    "    for feature in record.features: \n",
    "        if feature.type == \"CDS\":\n",
    "            locus_tag = feature.qualifiers.get(\"locus_tag\", [\"\"])[0]\n",
    "            gene = feature.qualifiers.get(\"gene\", [\"\"])[0]\n",
    "            product = feature.qualifiers.get(\"product\", [\"\"])[0]\n",
    "\n",
    "            if tag in [locus_tag, gene, product] or short_tag in [locus_tag, gene, product]:\n",
    "                protein = feature.qualifiers.get(\"translation\", [\"TRANSLATION_NOT_FOUND\"])[0]\n",
    "                dna_seq = feature.location.extract(record.seq)\n",
    "                return (protein, str(dna_seq))\n",
    "\n",
    "    return (\"NOT_FOUND\", \"NOT_FOUND\")\n",
    "\n",
    "# ---- MAIN PROCESSING ----\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if not file_name.endswith(\".tsv\"):\n",
    "        continue\n",
    "\n",
    "    print(f\"ðŸ” Processing: {file_name}\")\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "    genome_acc = genome_mapping.get(file_name)\n",
    "    if not genome_acc:\n",
    "        print(f\"âš  No genome accession mapped for {file_name}\")\n",
    "        continue\n",
    "\n",
    "    protein_seqs = []\n",
    "    dna_seqs = []\n",
    "\n",
    "    for geneid in df[\"Geneid\"]:\n",
    "        protein, dna = get_sequences_from_geneid(genome_acc, geneid)\n",
    "        protein_seqs.append(protein)\n",
    "        dna_seqs.append(dna)\n",
    "\n",
    "    df[\"ProteinSequence\"] = protein_seqs\n",
    "    df[\"DNASequence\"] = dna_seqs\n",
    "\n",
    "    out_path = os.path.join(output_folder, file_name)\n",
    "    df.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "    print(f\"âœ… Saved to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5e7b6e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Failed sequence extractions found in the following files:\n",
      "\n",
      "ðŸ“„ Finstrlova_Newman_full_raw_counts_tpm_filtered_classified.tsv â€” 4 failures\n",
      "               Geneid ProteinSequence DNASequence\n",
      "gene-CPT_phageK_gt004       NOT_FOUND   NOT_FOUND\n",
      "gene-CPT_phageK_gt002       NOT_FOUND   NOT_FOUND\n",
      "gene-CPT_phageK_gt003       NOT_FOUND   NOT_FOUND\n",
      "gene-CPT_phageK_gt001       NOT_FOUND   NOT_FOUND\n",
      "------------------------------------------------------------\n",
      "ðŸ“„ Guegler_T4_minusToxIN_full_raw_counts_tpm_filtered_classified.tsv â€” 10 failures\n",
      "     Geneid ProteinSequence DNASequence\n",
      "gene-T4t006       NOT_FOUND   NOT_FOUND\n",
      "gene-T4t003       NOT_FOUND   NOT_FOUND\n",
      "gene-T4t008       NOT_FOUND   NOT_FOUND\n",
      "gene-T4t007       NOT_FOUND   NOT_FOUND\n",
      "gene-T4s002       NOT_FOUND   NOT_FOUND\n",
      "gene-T4t001       NOT_FOUND   NOT_FOUND\n",
      "gene-T4s001       NOT_FOUND   NOT_FOUND\n",
      "gene-T4t002       NOT_FOUND   NOT_FOUND\n",
      "gene-T4t004       NOT_FOUND   NOT_FOUND\n",
      "gene-T4t005       NOT_FOUND   NOT_FOUND\n",
      "------------------------------------------------------------\n",
      "ðŸ“„ Lood_full_raw_counts_tpm_filtered_classified.tsv â€” 16 failures\n",
      "         Geneid ProteinSequence DNASequence\n",
      "gene-EST35_0396       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0036       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0406       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0394       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0398       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0393       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0353       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0397       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0414       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0413       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0407       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0395       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0068       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0403       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0408       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0168       NOT_FOUND   NOT_FOUND\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Folder containing your result files\n",
    "results_folder = \"../data/feature_extraction\"\n",
    "\n",
    "# Keywords to look for in failed extractions\n",
    "failure_keywords = [\"NOT_FOUND\", \"ERROR_FETCH\", \"TRANSLATION_NOT_FOUND\"]\n",
    "\n",
    "# Storage for summary\n",
    "summary = {}\n",
    "\n",
    "# Loop through all TSV files\n",
    "for file_name in os.listdir(results_folder):\n",
    "    if not file_name.endswith(\".tsv\"):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(results_folder, file_name)\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "    failed_rows = df[\n",
    "        df[\"ProteinSequence\"].isin(failure_keywords) |\n",
    "        df[\"DNASequence\"].isin(failure_keywords)\n",
    "    ]\n",
    "\n",
    "    if not failed_rows.empty:\n",
    "        summary[file_name] = failed_rows[[\"Geneid\", \"ProteinSequence\", \"DNASequence\"]]\n",
    "\n",
    "# Report the results\n",
    "if summary:\n",
    "    print(\"âŒ Failed sequence extractions found in the following files:\\n\")\n",
    "    for fname, failures in summary.items():\n",
    "        print(f\"ðŸ“„ {fname} â€” {len(failures)} failures\")\n",
    "        print(failures.to_string(index=False))\n",
    "        print(\"-\" * 60)\n",
    "else:\n",
    "    print(\"âœ… All sequence extractions succeeded. No issues found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec687d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "047688c9",
   "metadata": {},
   "source": [
    "# User-story 11: Sequence based features\n",
    "@LuiseJedlitschka\n",
    "@milli2908\n",
    "@elivic734\n",
    "\n",
    "## Potential features:\n",
    "- **CG-count**: Despite being a simple metric, GC presents a huge variation across genomes (ranging from approximately 20% to 70% ). GC content is reasonably constant within a given genome, and was already found to be correlated with several universal factors of microbial lifestyles such as temperature, niche complexity and aerobiosis [Genomic Signature](https://www.sciencedirect.com/topics/biochemistry-genetics-and-molecular-biology/genomic-signature).\n",
    "- **sequence-length**\n",
    "- **K-Mer-frequency**: e.g. k3 -> codon composition\n",
    "- **nucleotide composition** (Base percentages and purin/pyrimidin percentages)\n",
    "- **pG bias**: relevant for interaction with host, methylation, epigenetic regulation, \n",
    " Interpretation:\n",
    "\n",
    "    CpG < 1: CpG is underrepresented\n",
    "\n",
    "    CpG â‰ˆ 1: expected frequency, no bias\n",
    "\n",
    "    CpG > 1: CpG is overrepresented\n",
    "- **motives**:\n",
    "\n",
    "    \"TATA_box\": \"TATAAA\",       # Promotor\n",
    "\n",
    "    \"CAAT_box\": \"GGCCAATCT\",    # Enhancer\n",
    "\n",
    "    \"PolyA_signal\": \"AATAAA\",   # Signal for transcriptation\n",
    "- **relative position in genome**\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "## User-story 13: integration of external insights\n",
    "[Genomic features of E. coli O177 phages](https://www.nature.com/articles/s41598-023-48788-w/tables/1): sequence length, GC-content\n",
    "\n",
    "*comparison*: also used as features in our model\n",
    "\n",
    "[DeepPL: A deep-learning-based tool for the prediction of bacteriophage lifecycle](https://pmc.ncbi.nlm.nih.gov/articles/PMC11521287/): K-mer 6 was selected in this study based on its best performance, as reported by DNABERT\n",
    "\n",
    "*comparison*: the sliding window approach is used to detect the Tricolons, as our input is not a whole genome but already specific geneso used in our model\n",
    "\n",
    "[Digital phagograms: predicting phage infectivity through a multilayer machine learning approach](https://www.sciencedirect.com/science/article/pii/S1879625721001620): \n",
    "Nucleotide composition, Codon composition, Codon usage bias (Codon usage bias refers to the differences in the frequency of usage for a certain base triplet for a given amino acid among organisms), GC content, CpG bias, k-mer frequeR spacers, Embeddings, pVOG hits  Coding DNA sequences\t(Auxiliary metabolic genes, Shared tRNAs, defense system genes, Physicochemical properties)\n",
    "\n",
    "*comparison*: only a few of these (nucleotide composition, Codon composition, GC content, k-mer frequencies, CpG bias) are used in our model as some are redundant with the structural features relying (pVOG hits, Coding DNA sequences, Physicochemical properties) on the protein sequence, some are only necessary when the and the host-genome (CRISPR spacers, Shared tRNAs, defense system genes) input is a whole genome, not just sequences like in our case, and some are just too specific considering our main focus is on the protein-sequences-features (Codon usage bias)\n",
    "\n",
    "[PhageAI - Bacteriophage Life Cycle Recognition with Machine Learning and Natural Language Processing](https://www.biorxiv.org/content/10.1101/2020.07.11.198606v1.full): sliding window approach using constant k = 6 and the Word2Vec algorithm with the Skip-gram model, nominal features were empirically chosen by feature selection algorithm called Feature ranking with recursive feature elimination and cross-validated selection of the best number of features using Support Vector Machine \n",
    "\n",
    "*comparison*: sliding window approach is used to detect the Tricolons, as our input is not a whole genome but already specific genes\n",
    "\n",
    "[Rapid discovery of novel prophages using biological feature engineering and machine learning](https://academic.oup.com/nargab/article/3/1/lqaa109/6066536?login=true): gc_content (also in specific positions of the codons), CAI (codon adaptation index, measures the codon usage bias), BP:percent (for all bases, purin, pyrimidin)\n",
    "\n",
    "*comparison*: the most important (gc_content and BP:percentage) are in our model, the others are very detailed and unnecessary as our features focus on protein sequenceson: also used in our model\n",
    "                                                                                                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8f60a48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features table saved as ../data/feature_table\n",
      "Features table saved as ../data/feature_table\n",
      "Features table saved as ../data/feature_table\n",
      "Features table saved as ../data/feature_table\n",
      "Features table saved as ../data/feature_table\n",
      "Features table saved as ../data/feature_table\n",
      "Features table saved as ../data/feature_table\n"
     ]
    }
   ],
   "source": [
    "# Load feature_extraction table\n",
    "input_path = Path('../data/feature_extraction')\n",
    "output_path = Path('../data/feature_table')\n",
    "gff_folder = Path(\"../data/features\")\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Computing k-mers + Counting k-mers for each sequence\n",
    "k = 3\n",
    "\n",
    "# Creates every possible k-mer of the length 3\n",
    "alphabet = [\"A\", \"T\", \"G\", \"C\"]\n",
    "all_kmers = [\"\".join(p) for p in product(alphabet, repeat=k)]\n",
    "top_k_features = 10\n",
    "\n",
    "# Helper function to count k-mers \n",
    "def count_kmers(seq, k):\n",
    "    seq = seq.upper()\n",
    "    counts = Counter(seq[i:i+k] for i in range(len(seq) - k + 1) if set(seq[i:i+k]).issubset(alphabet))\n",
    "    return [counts.get(kmer, 0) for kmer in all_kmers] # returns a list with amount of each k-mer of a sequence\n",
    "    \n",
    "for file in input_path.glob(\"*.tsv\"):\n",
    "    df = pd.read_csv(file, sep=\"\\t\")\n",
    "    \n",
    "    # Only keep relevant columns\n",
    "    df_features = df[[\"Geneid\", \"DNASequence\", \"classification\"]].copy()\n",
    "\n",
    "    # Extracting Gene positions from GFF\n",
    "    base_name = file.name.split(\"_\")[0].lower()\n",
    "    gff_match = None\n",
    "    for gff_file in gff_folder.glob(\"*.gff3\"):\n",
    "        if gff_file.name.lower().startswith(base_name):\n",
    "            gff_match = gff_file\n",
    "            break\n",
    "    if gff_match:\n",
    "        gene_positions = {}\n",
    "        # Parse the GFF file to extract gene positions\n",
    "        with open(gff_match) as in_handle:\n",
    "            for rec in GFF.parse(in_handle):\n",
    "                genome_length = len(rec)\n",
    "                for feature in rec.features:\n",
    "                    if feature.type == \"gene\":\n",
    "                        gene_id = feature.id\n",
    "                        start = int(feature.location.start)\n",
    "                        end = int(feature.location.end)\n",
    "                        midpoint = (start + end) // 2\n",
    "                        gene_positions[gene_id] = (start, end, midpoint)\n",
    "        # Mapping the gene positions to the feature table                \n",
    "        df_features[\"Gene_Position_Start\"] = df_features[\"Geneid\"].map(lambda gid: gene_positions.get(gid, (None, None, None))[0])\n",
    "        df_features[\"Gene_Position_End\"] = df_features[\"Geneid\"].map(lambda gid: gene_positions.get(gid, (None, None, None))[1])\n",
    "        df_features[\"Gene_Position_Midpoint\"] = df_features[\"Geneid\"].map(lambda gid: gene_positions.get(gid, (None, None, None))[2])\n",
    "        # Calculate the relative position of each gene ( midpoint / genome length)\n",
    "        df_features[\"Gene_Position_Relative\"] = df_features[\"Gene_Position_Midpoint\"].apply(lambda x: x / genome_length if x is not None else None)\n",
    "        # Remove Start, End and Midpoint columns\n",
    "        df_features.drop([\"Gene_Position_Start\", \"Gene_Position_End\", \"Gene_Position_Midpoint\"], axis=1, inplace=True)\n",
    "    else:\n",
    "        print(f\"No GFF found for {file.name}, skipping position features.\")\n",
    "\n",
    "\n",
    "    # Computing GC-content for each sequence\n",
    "    df_features[\"GC_Content\"] = df_features[\"DNASequence\"].apply(lambda seq: gc_fraction(Seq(seq)))\n",
    "\n",
    "      \n",
    "    # Computing sequence length for each DNA sequence                                                      \n",
    "    df_features[\"Seq_length\"] = df_features[\"DNASequence\"].apply(lambda seq: len(seq) if isinstance(seq, str) else 0) \n",
    "\n",
    "    # Function to count bases\n",
    "    def count_bases(seq):\n",
    "        seq = seq.upper()\n",
    "        return {\n",
    "            \"A_Content\": seq.count(\"A\"),\n",
    "            \"T_Content\": seq.count(\"T\"),\n",
    "            \"G_Content\": seq.count(\"G\"),\n",
    "            \"C_Content\": seq.count(\"C\")\n",
    "        }\n",
    "    \n",
    "    motives = {\n",
    "        \"TATA_box\": \"TATAAA\",       # Promotor\n",
    "        \"CAAT_box\": \"GGCCAATCT\",    # Enhancer\n",
    "        \"PolyA_signal\": \"AATAAA\",   # Signal for transcriptation\n",
    "    }\n",
    "\n",
    "    def count_motives(sequence, motives):\n",
    "        sequence = sequence.upper()\n",
    "        result = {}\n",
    "        for name, pattern in motives.items():\n",
    "            result[f\"motive_{name}\"] = len(re.findall(pattern, sequence))\n",
    "        return result\n",
    "    \n",
    "    # Counting bases A,G,C and T\n",
    "    base_counts = df_features[\"DNASequence\"].apply(count_bases).apply(pd.Series)\n",
    "    base_fractions = base_counts.div(df_features[\"Seq_length\"], axis=0)\n",
    "    df_features = pd.concat([df_features, base_fractions], axis=1)\n",
    "    \n",
    "    # Counting Purin (A + G) and Pyrimidin (C + T)\n",
    "    df_features[\"Purin_Content\"] = df_features[\"DNASequence\"].apply(lambda seq: (seq.count(\"A\") + seq.count(\"G\")) / len(seq))\n",
    "    df_features[\"Pyrimidin_Content\"] = df_features[\"DNASequence\"].apply(lambda seq: (seq.count(\"C\") + seq.count(\"T\")) / len(seq))\n",
    "    \n",
    "    # Computing CpG bias\n",
    "    def calc_cpg_bias(row):\n",
    "        # Annahme: row['DNASequence'], row['G-content'], row['C-content'], row['Seq_length'] existieren\n",
    "        seq = row['DNASequence'].upper()\n",
    "        c_count = seq.count(\"C\")\n",
    "        g_count = seq.count(\"G\")\n",
    "        seq_length = len(seq)\n",
    "        cpg_count = sum(1 for i in range(seq_length-1) if seq[i:i+2] == \"CG\")\n",
    "        expected = (c_count * g_count) / seq_length if seq_length > 0 else 0\n",
    "        return (cpg_count / expected) if expected > 0 else 0\n",
    "\n",
    "    df_features[\"CpG_bias\"] = df_features.apply(calc_cpg_bias, axis=1)\n",
    "\n",
    "    \n",
    "    # Counting motives\n",
    "    motive_features_rel = df_features.apply(\n",
    "    lambda row: pd.Series({f\"{k}_rel\": v / row[\"Seq_length\"] if row[\"Seq_length\"] > 0 else 0\n",
    "                           for k, v in count_motives(row[\"DNASequence\"], motives).items()}),\n",
    "    axis=1\n",
    "    )\n",
    "    df_features = pd.concat([df_features, motive_features_rel], axis=1)\n",
    "    \n",
    "    # k-mer counting\n",
    "    kmer_counts = df_features[\"DNASequence\"].apply(lambda seq: count_kmers(seq, k))\n",
    "    kmer_df = pd.DataFrame(kmer_counts.tolist(), columns=[f'kmer_{kmer}' for kmer in all_kmers])\n",
    "\n",
    "    # Normalize k-mer counts\n",
    "    kmer_sums = kmer_df.sum(axis=1).replace(0, 1)\n",
    "    kmer_df_norm = kmer_df.div(kmer_sums, axis=0)\n",
    "\n",
    "    \n",
    "    # Save as new TSV\n",
    "    df_out = pd.concat([df_features, kmer_df_norm], axis=1)\n",
    "    out_file = output_path / file.name\n",
    "    df_out.to_csv(out_file, sep=\"\\t\", index=False)\n",
    "    print(f\"Features table saved as {output_path}\")    \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vividVirions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
