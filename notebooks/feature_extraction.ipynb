{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed2757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez, SeqIO\n",
    "from Bio.SeqUtils import gc_fraction\n",
    "from Bio.Seq import Seq\n",
    "from itertools import product\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from BCBio import GFF\n",
    "import re\n",
    "import itertools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8548bd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Processing: Brandao_MCCM_full_raw_counts_tpm_filtered_classified.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lelo3/anaconda3/envs/vividVirions/lib/python3.13/site-packages/Bio/Entrez/__init__.py:734: UserWarning: \n",
      "            Email address is not specified.\n",
      "\n",
      "            To make use of NCBI's E-utilities, NCBI requires you to specify your\n",
      "            email address with each request.  As an example, if your email address\n",
      "            is A.N.Other@example.com, you can specify it as follows:\n",
      "               from Bio import Entrez\n",
      "               Entrez.email = 'A.N.Other@example.com'\n",
      "            In case of excessive usage of the E-utilities, NCBI will attempt to contact\n",
      "            a user at the email address provided before blocking access to the\n",
      "            E-utilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     59\u001b[39m dna_seqs = []\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m geneid \u001b[38;5;129;01min\u001b[39;00m df[\u001b[33m\"\u001b[39m\u001b[33mGeneid\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     protein, dna = get_sequences_from_geneid(genome_acc, geneid)\n\u001b[32m     63\u001b[39m     protein_seqs.append(protein)\n\u001b[32m     64\u001b[39m     dna_seqs.append(dna)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mget_sequences_from_geneid\u001b[39m\u001b[34m(genome_accession, geneid)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_sequences_from_geneid\u001b[39m(genome_accession, geneid):\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m         handle = Entrez.efetch(db=\u001b[33m\"\u001b[39m\u001b[33mnucleotide\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mid\u001b[39m=genome_accession, rettype=\u001b[33m\"\u001b[39m\u001b[33mgb\u001b[39m\u001b[33m\"\u001b[39m, retmode=\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m         record = SeqIO.read(handle, \u001b[33m\"\u001b[39m\u001b[33mgenbank\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m         handle.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/vividVirions/lib/python3.13/site-packages/Bio/Entrez/__init__.py:201\u001b[39m, in \u001b[36mefetch\u001b[39m\u001b[34m(db, **keywords)\u001b[39m\n\u001b[32m    199\u001b[39m variables.update(keywords)\n\u001b[32m    200\u001b[39m request = _build_request(cgi, variables)\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _open(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/vividVirions/lib/python3.13/site-packages/Bio/Entrez/__init__.py:634\u001b[39m, in \u001b[36m_open\u001b[39m\u001b[34m(request)\u001b[39m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_tries):\n\u001b[32m    633\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m         handle = urlopen(request)\n\u001b[32m    635\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m    636\u001b[39m         \u001b[38;5;66;03m# Reraise if the final try fails\u001b[39;00m\n\u001b[32m    637\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m i >= max_tries - \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/vividVirions/lib/python3.13/urllib/request.py:189\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, context)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    188\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m opener.open(url, data, timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/vividVirions/lib/python3.13/urllib/request.py:489\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    486\u001b[39m     req = meth(req)\n\u001b[32m    488\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m response = \u001b[38;5;28mself\u001b[39m._open(req, data)\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    492\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/vividVirions/lib/python3.13/urllib/request.py:506\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    503\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    505\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m result = \u001b[38;5;28mself\u001b[39m._call_chain(\u001b[38;5;28mself\u001b[39m.handle_open, protocol, protocol +\n\u001b[32m    507\u001b[39m                           \u001b[33m'\u001b[39m\u001b[33m_open\u001b[39m\u001b[33m'\u001b[39m, req)\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/vividVirions/lib/python3.13/urllib/request.py:466\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    465\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     result = func(*args)\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    468\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/vividVirions/lib/python3.13/urllib/request.py:1367\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1366\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.do_open(http.client.HTTPSConnection, req,\n\u001b[32m   1368\u001b[39m                         context=\u001b[38;5;28mself\u001b[39m._context)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/vividVirions/lib/python3.13/urllib/request.py:1323\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1321\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m   1322\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[32m-> \u001b[39m\u001b[32m1323\u001b[39m     r = h.getresponse()\n\u001b[32m   1324\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1325\u001b[39m     h.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/vividVirions/lib/python3.13/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         response.begin()\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/vividVirions/lib/python3.13/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28mself\u001b[39m._read_status()\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/vividVirions/lib/python3.13/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/vividVirions/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sock.recv_into(b)\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/vividVirions/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read(nbytes, buffer)\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/vividVirions/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "input_folder = \"../data/classified\"\n",
    "output_folder = \"../data/feature_extraction\"\n",
    "\n",
    "# Map each input file to its matching genome accession\n",
    "genome_mapping = {\n",
    "    \"Brandao_MCCM_full_raw_counts_tpm_filtered_classified.tsv\": \"NC_010326\",\n",
    "    \"Finstrlova_Newman_full_raw_counts_tpm_filtered_classified.tsv\": \"NC_005880\",\n",
    "    \"Guegler_T4_minusToxIN_full_raw_counts_tpm_filtered_classified.tsv\": \"NC_000866\",\n",
    "    \"Guegler_T7_plusToxIN_full_raw_counts_tpm_filtered_classified.tsv\": \"NC_001604\",\n",
    "    \"Lood_full_raw_counts_tpm_filtered_classified.tsv\": \"MK797984.1\",\n",
    "    \"Sprenger_VC_WT_VP882_delta_cpdS_full_raw_counts_tpm_filtered_classified.tsv\": \"NC_009016.1\",\n",
    "    \"Yang_full_raw_counts_tpm_filtered_classified.tsv\": \"NC_021316\",\n",
    "}\n",
    "\n",
    "# Make sure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# ---- FUNCTION TO GET PROTEIN + DNA SEQUENCE ----\n",
    "def get_sequences_from_geneid(genome_accession, geneid):\n",
    "    try:\n",
    "        handle = Entrez.efetch(db=\"nucleotide\", id=genome_accession, rettype=\"gb\", retmode=\"text\")\n",
    "        record = SeqIO.read(handle, \"genbank\")\n",
    "        handle.close()\n",
    "    except Exception as e:\n",
    "        print(f\"âš  Failed to fetch {genome_accession}: {e}\")\n",
    "        return (\"ERROR_FETCH\", \"ERROR_FETCH\")\n",
    "\n",
    "    tag = geneid.replace(\"gene-\", \"\").strip()\n",
    "    short_tag = tag.split(\"_\")[-1]\n",
    "\n",
    "    for feature in record.features: \n",
    "        if feature.type == \"CDS\":\n",
    "            locus_tag = feature.qualifiers.get(\"locus_tag\", [\"\"])[0]\n",
    "            gene = feature.qualifiers.get(\"gene\", [\"\"])[0]\n",
    "            product = feature.qualifiers.get(\"product\", [\"\"])[0]\n",
    "\n",
    "            if tag in [locus_tag, gene, product] or short_tag in [locus_tag, gene, product]:\n",
    "                protein = feature.qualifiers.get(\"translation\", [\"TRANSLATION_NOT_FOUND\"])[0]\n",
    "                dna_seq = feature.location.extract(record.seq)\n",
    "                return (protein, str(dna_seq))\n",
    "\n",
    "    return (\"NOT_FOUND\", \"NOT_FOUND\")\n",
    "\n",
    "# ---- MAIN PROCESSING ----\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if not file_name.endswith(\".tsv\"):\n",
    "        continue\n",
    "\n",
    "    print(f\"ðŸ” Processing: {file_name}\")\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "    genome_acc = genome_mapping.get(file_name)\n",
    "    if not genome_acc:\n",
    "        print(f\"âš  No genome accession mapped for {file_name}\")\n",
    "        continue\n",
    "\n",
    "    protein_seqs = []\n",
    "    dna_seqs = []\n",
    "\n",
    "    for geneid in df[\"Geneid\"]:\n",
    "        protein, dna = get_sequences_from_geneid(genome_acc, geneid)\n",
    "        protein_seqs.append(protein)\n",
    "        dna_seqs.append(dna)\n",
    "\n",
    "    df[\"ProteinSequence\"] = protein_seqs\n",
    "    df[\"DNASequence\"] = dna_seqs\n",
    "\n",
    "    out_path = os.path.join(output_folder, file_name)\n",
    "    df.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "    print(f\"âœ… Saved to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7b6e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Failed sequence extractions found in the following files:\n",
      "\n",
      "ðŸ“„ Finstrlova_Newman_full_raw_counts_tpm_filtered_classified.tsv â€” 4 failures\n",
      "               Geneid ProteinSequence DNASequence\n",
      "gene-CPT_phageK_gt004       NOT_FOUND   NOT_FOUND\n",
      "gene-CPT_phageK_gt002       NOT_FOUND   NOT_FOUND\n",
      "gene-CPT_phageK_gt003       NOT_FOUND   NOT_FOUND\n",
      "gene-CPT_phageK_gt001       NOT_FOUND   NOT_FOUND\n",
      "------------------------------------------------------------\n",
      "ðŸ“„ Guegler_T4_minusToxIN_full_raw_counts_tpm_filtered_classified.tsv â€” 10 failures\n",
      "     Geneid ProteinSequence DNASequence\n",
      "gene-T4t006       NOT_FOUND   NOT_FOUND\n",
      "gene-T4t003       NOT_FOUND   NOT_FOUND\n",
      "gene-T4t008       NOT_FOUND   NOT_FOUND\n",
      "gene-T4t007       NOT_FOUND   NOT_FOUND\n",
      "gene-T4s002       NOT_FOUND   NOT_FOUND\n",
      "gene-T4t001       NOT_FOUND   NOT_FOUND\n",
      "gene-T4s001       NOT_FOUND   NOT_FOUND\n",
      "gene-T4t002       NOT_FOUND   NOT_FOUND\n",
      "gene-T4t004       NOT_FOUND   NOT_FOUND\n",
      "gene-T4t005       NOT_FOUND   NOT_FOUND\n",
      "------------------------------------------------------------\n",
      "ðŸ“„ Lood_full_raw_counts_tpm_filtered_classified.tsv â€” 16 failures\n",
      "         Geneid ProteinSequence DNASequence\n",
      "gene-EST35_0396       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0036       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0406       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0394       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0398       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0393       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0353       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0397       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0414       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0413       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0407       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0395       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0068       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0403       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0408       NOT_FOUND   NOT_FOUND\n",
      "gene-EST35_0168       NOT_FOUND   NOT_FOUND\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Folder containing your result files\n",
    "results_folder = \"../data/feature_extraction\"\n",
    "\n",
    "# Keywords to look for in failed extractions\n",
    "failure_keywords = [\"NOT_FOUND\", \"ERROR_FETCH\", \"TRANSLATION_NOT_FOUND\"]\n",
    "\n",
    "# Storage for summary\n",
    "summary = {}\n",
    "\n",
    "# Loop through all TSV files\n",
    "for file_name in os.listdir(results_folder):\n",
    "    if not file_name.endswith(\".tsv\"):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(results_folder, file_name)\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "    failed_rows = df[\n",
    "        df[\"ProteinSequence\"].isin(failure_keywords) |\n",
    "        df[\"DNASequence\"].isin(failure_keywords)\n",
    "    ]\n",
    "\n",
    "    if not failed_rows.empty:\n",
    "        summary[file_name] = failed_rows[[\"Geneid\", \"ProteinSequence\", \"DNASequence\"]]\n",
    "\n",
    "# Report the results\n",
    "if summary:\n",
    "    print(\"âŒ Failed sequence extractions found in the following files:\\n\")\n",
    "    for fname, failures in summary.items():\n",
    "        print(f\"ðŸ“„ {fname} â€” {len(failures)} failures\")\n",
    "        print(failures.to_string(index=False))\n",
    "        print(\"-\" * 60)\n",
    "else:\n",
    "    print(\"âœ… All sequence extractions succeeded. No issues found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec687d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "047688c9",
   "metadata": {},
   "source": [
    "# User-story 11: Sequence based features\n",
    "@LuiseJedlitschka  \n",
    "@milli2908  \n",
    "@elivic734    \n",
    "    \n",
    "## Potential features:\n",
    "- **CG-count**: Despite being a simple metric, GC presents a huge variation across genomes (ranging from approximately 20% to 70% ). GC content is reasonably constant within a given genome, and was already found to be correlated with several universal factors of microbial lifestyles such as temperature, niche complexity and aerobiosis [Genomic Signature](https://www.sciencedirect.com/topics/biochemistry-genetics-and-molecular-biology/genomic-signature).\n",
    "- **sequence-length**\n",
    "- **K-Mer-frequency**: e.g. k3 -> codon composition\n",
    "- **nucleotide composition** (Base percentages and purin/pyrimidin percentages)\n",
    "- **CpG bias**: relevant for interaction with host, methylation, epigenetic regulation, \n",
    " Interpretation:\n",
    "\n",
    "    CpG < 1: CpG is underrepresented\n",
    "\n",
    "    CpG â‰ˆ 1: expected frequency, no bias\n",
    "\n",
    "    CpG > 1: CpG is overrepresented\n",
    "- **motives**:\n",
    "\n",
    "    \"TATA_box\": \"TATAAA\",       # Promotor\n",
    "\n",
    "    \"CAAT_box\": \"GGCCAATCT\",    # Enhancer\n",
    "\n",
    "    \"PolyA_signal\": \"AATAAA\",   # Signal for transcriptation\n",
    "- **relative position in genome**\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "## User-story 13: integration of external insights\n",
    "@LuiseJedlitschka  \n",
    "@milli2908  \n",
    "@elivic734    \n",
    "  \n",
    "[Genomic features of E. coli O177 phages](https://www.nature.com/articles/s41598-023-48788-w/tables/1): sequence length, GC-content\n",
    "\n",
    "*comparison*: also used as features in our model\n",
    "\n",
    "[DeepPL: A deep-learning-based tool for the prediction of bacteriophage lifecycle](https://pmc.ncbi.nlm.nih.gov/articles/PMC11521287/): K-mer 6 was selected in this study based on its best performance, as reported by DNABERT\n",
    "\n",
    "*comparison*: the sliding window approach is used to detect the Tricolons, as our input is not a whole genome but already specific geneso used in our model\n",
    "\n",
    "[Digital phagograms: predicting phage infectivity through a multilayer machine learning approach](https://www.sciencedirect.com/science/article/pii/S1879625721001620): \n",
    "Nucleotide composition, Codon composition, Codon usage bias (Codon usage bias refers to the differences in the frequency of usage for a certain base triplet for a given amino acid among organisms), GC content, CpG bias, k-mer frequeR spacers, Embeddings, pVOG hits  Coding DNA sequences\t(Auxiliary metabolic genes, Shared tRNAs, defense system genes, Physicochemical properties)\n",
    "\n",
    "*comparison*: only a few of these (nucleotide composition, Codon composition, GC content, k-mer frequencies, CpG bias) are used in our model as some are redundant with the structural features relying (pVOG hits, Coding DNA sequences, Physicochemical properties) on the protein sequence, some are only necessary when the and the host-genome (CRISPR spacers, Shared tRNAs, defense system genes) input is a whole genome, not just sequences like in our case, and some are just too specific considering our main focus is on the protein-sequences-features (Codon usage bias)\n",
    "\n",
    "[PhageAI - Bacteriophage Life Cycle Recognition with Machine Learning and Natural Language Processing](https://www.biorxiv.org/content/10.1101/2020.07.11.198606v1.full): sliding window approach using constant k = 6 and the Word2Vec algorithm with the Skip-gram model, nominal features were empirically chosen by feature selection algorithm called Feature ranking with recursive feature elimination and cross-validated selection of the best number of features using Support Vector Machine \n",
    "\n",
    "*comparison*: sliding window approach is used to detect the Tricolons, as our input is not a whole genome but already specific genes\n",
    "\n",
    "[Rapid discovery of novel prophages using biological feature engineering and machine learning](https://academic.oup.com/nargab/article/3/1/lqaa109/6066536?login=true): gc_content (also in specific positions of the codons), CAI (codon adaptation index, measures the codon usage bias), BP:percent (for all bases, purin, pyrimidin)\n",
    "\n",
    "*comparison*: the most important (gc_content and BP:percentage) are in our model, the others are very detailed and unnecessary as our features focus on protein sequenceson: also used in our model\n",
    "                                                                                                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f60a48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features table saved as ../data/dna_feature_table\n",
      "Features table saved as ../data/dna_feature_table\n",
      "Features table saved as ../data/dna_feature_table\n",
      "Features table saved as ../data/dna_feature_table\n",
      "Features table saved as ../data/dna_feature_table\n",
      "Features table saved as ../data/dna_feature_table\n",
      "Features table saved as ../data/dna_feature_table\n"
     ]
    }
   ],
   "source": [
    "# Load feature_extraction table\n",
    "input_path = Path('../data/feature_extraction')\n",
    "output_path = Path('../data/dna_feature_table')\n",
    "gff_folder = Path(\"../data/features\")\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Computing k-mers + Counting k-mers for each sequence\n",
    "k = 3\n",
    "\n",
    "# Creates every possible k-mer of the length 3\n",
    "alphabet = [\"A\", \"T\", \"G\", \"C\"]\n",
    "all_kmers = [\"\".join(p) for p in product(alphabet, repeat=k)]\n",
    "top_k_features = 10\n",
    "\n",
    "# Helper function to count k-mers \n",
    "def count_kmers(seq, k):\n",
    "    seq = seq.upper()\n",
    "    counts = Counter(seq[i:i+k] for i in range(len(seq) - k + 1) if set(seq[i:i+k]).issubset(alphabet))\n",
    "    return [counts.get(kmer, 0) for kmer in all_kmers] # returns a list with amount of each k-mer of a sequence\n",
    "    \n",
    "for file in input_path.glob(\"*.tsv\"):\n",
    "    df = pd.read_csv(file, sep=\"\\t\")\n",
    "    \n",
    "    # Only keep relevant columns\n",
    "    df_features = df[[\"Geneid\", \"DNASequence\", \"classification\"]].copy()\n",
    "\n",
    "    # Extracting Gene positions from GFF\n",
    "    base_name = file.name.split(\"_\")[0].lower()\n",
    "    gff_match = None\n",
    "    for gff_file in gff_folder.glob(\"*.gff3\"):\n",
    "        if gff_file.name.lower().startswith(base_name):\n",
    "            gff_match = gff_file\n",
    "            break\n",
    "    if gff_match:\n",
    "        gene_positions = {}\n",
    "        # Parse the GFF file to extract gene positions\n",
    "        with open(gff_match) as in_handle:\n",
    "            for rec in GFF.parse(in_handle):\n",
    "                genome_length = len(rec)\n",
    "                for feature in rec.features:\n",
    "                    if feature.type == \"gene\":\n",
    "                        gene_id = feature.id\n",
    "                        start = int(feature.location.start)\n",
    "                        end = int(feature.location.end)\n",
    "                        midpoint = (start + end) // 2\n",
    "                        gene_positions[gene_id] = (start, end, midpoint)\n",
    "        # Mapping the gene positions to the feature table                \n",
    "        df_features[\"Gene_Position_Start\"] = df_features[\"Geneid\"].map(lambda gid: gene_positions.get(gid, (None, None, None))[0])\n",
    "        df_features[\"Gene_Position_End\"] = df_features[\"Geneid\"].map(lambda gid: gene_positions.get(gid, (None, None, None))[1])\n",
    "        df_features[\"Gene_Position_Midpoint\"] = df_features[\"Geneid\"].map(lambda gid: gene_positions.get(gid, (None, None, None))[2])\n",
    "        # Calculate the relative position of each gene ( midpoint / genome length)\n",
    "        df_features[\"Gene_Position_Relative\"] = df_features[\"Gene_Position_Midpoint\"].apply(lambda x: x / genome_length if x is not None else None)\n",
    "        # Remove Start, End and Midpoint columns\n",
    "        df_features.drop([\"Gene_Position_Start\", \"Gene_Position_End\", \"Gene_Position_Midpoint\"], axis=1, inplace=True)\n",
    "    else:\n",
    "        print(f\"No GFF found for {file.name}, skipping position features.\")\n",
    "\n",
    "\n",
    "    # Computing GC-content for each sequence\n",
    "    df_features[\"GC_Content\"] = df_features[\"DNASequence\"].apply(lambda seq: gc_fraction(Seq(seq)))\n",
    "\n",
    "      \n",
    "    # Computing sequence length for each DNA sequence                                                      \n",
    "    df_features[\"Seq_length\"] = df_features[\"DNASequence\"].apply(lambda seq: len(seq) if isinstance(seq, str) else 0) \n",
    "\n",
    "    # Function to count bases\n",
    "    def count_bases(seq):\n",
    "        seq = seq.upper()\n",
    "        return {\n",
    "            \"A_Content\": seq.count(\"A\"),\n",
    "            \"T_Content\": seq.count(\"T\"),\n",
    "            \"G_Content\": seq.count(\"G\"),\n",
    "            \"C_Content\": seq.count(\"C\")\n",
    "        }\n",
    "    \n",
    "    motives = {\n",
    "        \"TATA_box\": \"TATAAA\",       # Promotor\n",
    "        \"CAAT_box\": \"GGCCAATCT\",    # Enhancer\n",
    "        \"PolyA_signal\": \"AATAAA\",   # Signal for transcriptation\n",
    "    }\n",
    "\n",
    "    def count_motives(sequence, motives):\n",
    "        sequence = sequence.upper()\n",
    "        result = {}\n",
    "        for name, pattern in motives.items():\n",
    "            result[f\"motive_{name}\"] = len(re.findall(pattern, sequence))\n",
    "        return result\n",
    "    \n",
    "    # Counting bases A,G,C and T\n",
    "    base_counts = df_features[\"DNASequence\"].apply(count_bases).apply(pd.Series)\n",
    "    base_fractions = base_counts.div(df_features[\"Seq_length\"], axis=0)\n",
    "    df_features = pd.concat([df_features, base_fractions], axis=1)\n",
    "    \n",
    "    # Counting Purin (A + G) and Pyrimidin (C + T)\n",
    "    df_features[\"Purin_Content\"] = df_features[\"DNASequence\"].apply(lambda seq: (seq.count(\"A\") + seq.count(\"G\")) / len(seq))\n",
    "    df_features[\"Pyrimidin_Content\"] = df_features[\"DNASequence\"].apply(lambda seq: (seq.count(\"C\") + seq.count(\"T\")) / len(seq))\n",
    "    \n",
    "    # Computing CpG bias\n",
    "    def calc_cpg_bias(row):\n",
    "        # Annahme: row['DNASequence'], row['G-content'], row['C-content'], row['Seq_length'] existieren\n",
    "        seq = row['DNASequence'].upper()\n",
    "        c_count = seq.count(\"C\")\n",
    "        g_count = seq.count(\"G\")\n",
    "        seq_length = len(seq)\n",
    "        cpg_count = sum(1 for i in range(seq_length-1) if seq[i:i+2] == \"CG\")\n",
    "        expected = (c_count * g_count) / seq_length if seq_length > 0 else 0\n",
    "        return (cpg_count / expected) if expected > 0 else 0\n",
    "\n",
    "    df_features[\"CpG_bias\"] = df_features.apply(calc_cpg_bias, axis=1)\n",
    "\n",
    "    \n",
    "    # Counting motives\n",
    "    motive_features_rel = df_features.apply(\n",
    "    lambda row: pd.Series({f\"{k}_rel\": v / row[\"Seq_length\"] if row[\"Seq_length\"] > 0 else 0\n",
    "                           for k, v in count_motives(row[\"DNASequence\"], motives).items()}),\n",
    "    axis=1\n",
    "    )\n",
    "    df_features = pd.concat([df_features, motive_features_rel], axis=1)\n",
    "    \n",
    "    # k-mer counting\n",
    "    kmer_counts = df_features[\"DNASequence\"].apply(lambda seq: count_kmers(seq, k))\n",
    "    kmer_df = pd.DataFrame(kmer_counts.tolist(), columns=[f'kmer_{kmer}' for kmer in all_kmers])\n",
    "\n",
    "    # Normalize k-mer counts\n",
    "    kmer_sums = kmer_df.sum(axis=1).replace(0, 1)\n",
    "    kmer_df_norm = kmer_df.div(kmer_sums, axis=0)\n",
    "\n",
    "    \n",
    "    # Save as new TSV\n",
    "    df_out = pd.concat([df_features, kmer_df_norm], axis=1)\n",
    "    out_file = output_path / file.name\n",
    "    df_out.to_csv(out_file, sep=\"\\t\", index=False)\n",
    "    print(f\"Features table saved as {output_path}\")    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5db4f3c",
   "metadata": {},
   "source": [
    "# User-story 11: Sequence based features\n",
    "@dottting  \n",
    "@davmar01\n",
    "\n",
    "The following code computes feature vectors for each sequence using amino acid composition (AAC) and dipeptide (k=2) frequencies, capturing both global and local sequence properties. The feature matrices are save at \"../features/protein_primary_k=1and2\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f707b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../features/protein/protein_primary_k=1_k=2\\Brandao_MCCM_full_raw_counts_tpm_filtered_classified_features.tsv\n",
      "Saved: ../features/protein/protein_primary_k=1_k=2\\Finstrlova_Newman_full_raw_counts_tpm_filtered_classified_features.tsv\n",
      "Saved: ../features/protein/protein_primary_k=1_k=2\\Guegler_T4_minusToxIN_full_raw_counts_tpm_filtered_classified_features.tsv\n",
      "Saved: ../features/protein/protein_primary_k=1_k=2\\Guegler_T7_plusToxIN_full_raw_counts_tpm_filtered_classified_features.tsv\n",
      "Saved: ../features/protein/protein_primary_k=1_k=2\\Lood_full_raw_counts_tpm_filtered_classified_features.tsv\n",
      "Saved: ../features/protein/protein_primary_k=1_k=2\\Sprenger_VC_WT_VP882_delta_cpdS_full_raw_counts_tpm_filtered_classified_features.tsv\n",
      "Saved: ../features/protein/protein_primary_k=1_k=2\\Yang_full_raw_counts_tpm_filtered_classified_features.tsv\n"
     ]
    }
   ],
   "source": [
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "\n",
    "input_folder = \"../data/feature_extraction\"\n",
    "output_folder = \"../features/protein/protein_primary_k=1_k=2\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# List of standard amino acids\n",
    "AA_LIST = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "\n",
    "# Generate all possible 2-mer combinations (dipeptides)\n",
    "DIPEPTIDES = [\"\".join(p) for p in product(AA_LIST, repeat=2)]\n",
    "\n",
    "\n",
    "def extract_aac_kmer_features(seq):\n",
    "    \"\"\"Extract AAC, dipeptide (k=2), and key physicochemical features from a protein sequence.\"\"\"\n",
    "    seq = seq.upper().replace(\"*\", \"\")\n",
    "    total_len = len(seq)\n",
    "\n",
    "    # AAC features\n",
    "    aac_counts = Counter(seq)\n",
    "    aac_features = {f\"AAC_{aa}\": aac_counts.get(aa, 0) / total_len for aa in AA_LIST}\n",
    "\n",
    "    # Dipeptide (k=2) features\n",
    "    kmer_counts = Counter(seq[i : i + 2] for i in range(len(seq) - 1))\n",
    "    total_kmers = sum(kmer_counts.values()) or 1  # avoid division by zero\n",
    "    kmer_features = {\n",
    "        f\"kmer_{dp}\": kmer_counts.get(dp, 0) / total_kmers for dp in DIPEPTIDES\n",
    "    }\n",
    "\n",
    "    # Physicochemical features\n",
    "    try:\n",
    "        analysis = ProteinAnalysis(seq)\n",
    "        pI = analysis.isoelectric_point()\n",
    "        gravy = analysis.gravy()\n",
    "        instability = analysis.instability_index()\n",
    "    except Exception:\n",
    "        pI, gravy, instability = None, None, None\n",
    "\n",
    "    extra_features = {\n",
    "        \"IsoelectricPoint\": pI,\n",
    "        \"GRAVY\": gravy,\n",
    "        \"InstabilityIndex\": instability,\n",
    "        \"seq_length\": total_len,\n",
    "    }\n",
    "\n",
    "    return {**aac_features, **kmer_features, **extra_features}\n",
    "\n",
    "\n",
    "# Process each .tsv file in the input directory\n",
    "for filename in os.listdir(input_folder):\n",
    "    if not filename.endswith(\".tsv\"):\n",
    "        continue\n",
    "\n",
    "    filepath = os.path.join(input_folder, filename)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, sep=\"\\t\")\n",
    "        df.columns = df.columns.str.strip().str.lower()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filename}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Check for required columns\n",
    "    required = {\"geneid\", \"classification\", \"proteinsequence\"}\n",
    "    if not required.issubset(df.columns):\n",
    "        print(f\"Skipping file {filename} â€“ required columns missing.\")\n",
    "        print(f\"Found columns: {df.columns.tolist()}\")\n",
    "        continue\n",
    "\n",
    "    # Extract features row-wise\n",
    "    all_features = []\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            feats = extract_aac_kmer_features(row[\"proteinsequence\"])\n",
    "            ordered_feats = {\n",
    "                \"Geneid\": row[\"geneid\"],\n",
    "                \"classification\": row[\"classification\"],\n",
    "                **feats,\n",
    "            }\n",
    "            all_features.append(ordered_feats)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in row with gene ID {row.get('geneid', 'unknown')}: {e}\")\n",
    "\n",
    "    # Save the resulting feature matrix\n",
    "    if all_features:\n",
    "        output_df = pd.DataFrame(all_features)\n",
    "        output_filename = filename.replace(\".tsv\", \"_features.tsv\")\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "        output_df.to_csv(output_path, sep=\"\\t\", index=False)\n",
    "        print(f\"Saved: {output_path}\")\n",
    "    else:\n",
    "        print(f\"No valid entries in {filename}, nothing saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a02e2d",
   "metadata": {},
   "source": [
    "### Tripedtide features (most commonly used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ad09012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved k=3+physicochemical features to: ../features/protein/protein_primary_table_k=3\\Brandao_MCCM_full_raw_counts_tpm_filtered_classified_k3_physchem.tsv\n",
      "Saved k=3+physicochemical features to: ../features/protein/protein_primary_table_k=3\\Finstrlova_Newman_full_raw_counts_tpm_filtered_classified_k3_physchem.tsv\n",
      "Saved k=3+physicochemical features to: ../features/protein/protein_primary_table_k=3\\Guegler_T4_minusToxIN_full_raw_counts_tpm_filtered_classified_k3_physchem.tsv\n",
      "Saved k=3+physicochemical features to: ../features/protein/protein_primary_table_k=3\\Guegler_T7_plusToxIN_full_raw_counts_tpm_filtered_classified_k3_physchem.tsv\n",
      "Saved k=3+physicochemical features to: ../features/protein/protein_primary_table_k=3\\Lood_full_raw_counts_tpm_filtered_classified_k3_physchem.tsv\n",
      "Saved k=3+physicochemical features to: ../features/protein/protein_primary_table_k=3\\Sprenger_VC_WT_VP882_delta_cpdS_full_raw_counts_tpm_filtered_classified_k3_physchem.tsv\n",
      "Saved k=3+physicochemical features to: ../features/protein/protein_primary_table_k=3\\Yang_full_raw_counts_tpm_filtered_classified_k3_physchem.tsv\n"
     ]
    }
   ],
   "source": [
    "output_folder = \"../features/protein/protein_primary_table_k=3\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "TRIPEPTIDES = [\"\".join(p) for p in product(AA_LIST, repeat=3)]\n",
    "\n",
    "def extract_k3_features(seq):\n",
    "    \"\"\"Extract tripeptide (k=3) frequency features + top 3 physicochemical features from a protein sequence.\"\"\"\n",
    "    seq = seq.upper().replace(\"*\", \"\")\n",
    "    \n",
    "    # Tripeptide features\n",
    "    tri_counts = Counter(seq[i:i+3] for i in range(len(seq) - 2))\n",
    "    total_tri = sum(tri_counts.values()) or 1\n",
    "    tri_features = {\n",
    "        f\"kmer3_{tp}\": tri_counts.get(tp, 0) / total_tri for tp in TRIPEPTIDES\n",
    "    }\n",
    "\n",
    "    # Physicochemical features\n",
    "    try:\n",
    "        analysis = ProteinAnalysis(seq)\n",
    "        pI = analysis.isoelectric_point()\n",
    "        gravy = analysis.gravy()\n",
    "        instability = analysis.instability_index()\n",
    "    except Exception:\n",
    "        pI, gravy, instability = None, None, None\n",
    "\n",
    "    extra_features = {\n",
    "        \"IsoelectricPoint\": pI,\n",
    "        \"GRAVY\": gravy,\n",
    "        \"InstabilityIndex\": instability,\n",
    "        \"seq_length\": len(seq),\n",
    "    }\n",
    "\n",
    "    return {**tri_features, **extra_features}\n",
    "\n",
    "# Process each .tsv file in the input directory\n",
    "for filename in os.listdir(input_folder):\n",
    "    if not filename.endswith(\".tsv\"):\n",
    "        continue\n",
    "\n",
    "    filepath = os.path.join(input_folder, filename)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, sep=\"\\t\")\n",
    "        df.columns = df.columns.str.strip().str.lower()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filename}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Check for required columns\n",
    "    required = {\"geneid\", \"classification\", \"proteinsequence\"}\n",
    "    if not required.issubset(df.columns):\n",
    "        print(f\"Skipping file {filename} â€“ required columns missing.\")\n",
    "        print(f\"Found columns: {df.columns.tolist()}\")\n",
    "        continue\n",
    "\n",
    "    # Extract features row-wise\n",
    "    all_features = []\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            feats = extract_k3_features(row[\"proteinsequence\"])\n",
    "            ordered_feats = {\n",
    "                \"Geneid\": row[\"geneid\"],\n",
    "                \"classification\": row[\"classification\"],\n",
    "                **feats,\n",
    "            }\n",
    "            all_features.append(ordered_feats)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in row with gene ID {row.get('geneid', 'unknown')}: {e}\")\n",
    "\n",
    "    # Save the resulting feature matrix\n",
    "    if all_features:\n",
    "        output_df = pd.DataFrame(all_features)\n",
    "        output_filename = filename.replace(\".tsv\", \"_k3_physchem.tsv\")\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "        output_df.to_csv(output_path, sep=\"\\t\", index=False)\n",
    "        print(f\"Saved k=3+physicochemical features to: {output_path}\")\n",
    "    else:\n",
    "        print(f\"No valid entries in {filename}, nothing saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001e7312",
   "metadata": {},
   "source": [
    "### Secondary Structure Features\n",
    "\n",
    "- Predict structures with ESM3  (see `data/protein_structures/pdb`)\n",
    "\n",
    "- Secondary-structure related\n",
    "  - Secondary-structure content (Î±-helices, Î²-sheets, coils)  \n",
    "  - Solvent accessibility  \n",
    "  - Secondary-structure transitions  \n",
    "\n",
    "- ESM3 embeddings (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af1a88e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VividVirions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
